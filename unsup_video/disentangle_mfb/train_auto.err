load mkl/2017.1 (LD_LIBRARY_PATH)
load CUDNN/5.1.10-cuda_8.0 (LD_LIBRARY_PATH, LIBRARY_PATH, C_INCLUDE_PATH, CPLUS_INCLUDE_PATH)
load intel-opencl/2016 (PATH, LD_LIBRARY_PATH, OPENCL_VENDOR_PATH, OPENCL_INC, OPENCL_LIB)
load python/3.6.0+_ML (PATH, MANPATH, LD_LIBRARY_PATH, C_INCLUDE_PATH, CPLUS_INCLUDE_PATH, PYTHONHOME, PYTHONPATH, THEANO_FLAGS)
W tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x27d1400
W tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x2835030
W tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x28389b0
WARNING:tensorflow:From autoencoder.py:250: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.
Instructions for updating:
Use `tf.global_variables_initializer` instead.
W tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 2.43GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
W tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 2.43GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
slurmstepd: *** JOB 759037 ON nvb16 CANCELLED AT 2017-06-07T15:59:37 DUE TO TIME LIMIT ***
